name: CI/CD Pipeline with UV

on:
  push:
    branches: [ main, develop, "0*" ]  # Feature branches pattern
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:  # Allow manual triggering

env:
  # UV configuration for faster builds
  UV_SYSTEM_PYTHON: "true"
  UV_COMPILE_BYTECODE: "true"
  UV_PYTHON_PREFERENCE: "only-managed"

jobs:
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11", "3.12", "3.13"]
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up UV
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
        
    - name: Set up Python ${{ matrix.python-version }}
      run: uv python install ${{ matrix.python-version }}
      
    - name: Create virtual environment
      run: uv venv --python ${{ matrix.python-version }}
      
    - name: Install dependencies
      run: uv sync --all-extras --dev
      
    - name: Verify installation
      run: |
        uv run python --version
        uv run python -c "import dankerchat; print(f'DankerChat {dankerchat.__version__} imported successfully')"
        
    - name: Run migration verification tests
      run: |
        uv run python tests/test_uv_installation.py
        uv run python tests/test_pyproject_creation.py
        uv run python tests/test_dependency_installation.py
        uv run python tests/test_virtual_environment.py
        uv run python tests/test_uv_commands.py
        
    - name: Run main test suite
      run: uv run pytest tests/ -v --cov=src/dankerchat --cov-report=xml --cov-report=term-missing
      
    - name: Upload coverage reports
      uses: codecov/codecov-action@v4
      if: matrix.python-version == '3.12'
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
        
  lint:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up UV
      uses: astral-sh/setup-uv@v3
      
    - name: Install dependencies
      run: uv sync --dev
      
    - name: Run ruff linting
      run: uv run ruff check src/ tests/ --output-format=github
      
    - name: Run ruff formatting check
      run: uv run ruff format --check src/ tests/
      
    - name: Run black formatting check
      run: uv run black --check src/ tests/
      
    - name: Run type checking with mypy
      run: uv run mypy src/dankerchat
      continue-on-error: true  # Don't fail CI on type errors during development
      
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up UV
      uses: astral-sh/setup-uv@v3
      
    - name: Install dependencies
      run: uv sync --dev
      
    - name: Run security audit
      run: |
        # Check for known security vulnerabilities
        uv run pip-audit || true  # Don't fail CI, just warn
        
    - name: Check for secrets in code
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: main
        head: HEAD
        
  build:
    name: Build Package
    runs-on: ubuntu-latest
    needs: [test, lint]
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up UV
      uses: astral-sh/setup-uv@v3
      
    - name: Install build dependencies
      run: uv sync --dev
      
    - name: Build package
      run: uv build
      
    - name: Verify package can be installed
      run: |
        uv pip install dist/*.whl
        uv run python -c "import dankerchat; print(f'Package installed: {dankerchat.__version__}')"
        
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist-${{ github.sha }}
        path: dist/
        retention-days: 30
        
  performance:
    name: Performance Benchmark  
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up UV
      uses: astral-sh/setup-uv@v3
      
    - name: Benchmark environment creation
      run: |
        echo "=== UV Performance Benchmark ==="
        
        # Clean environment
        rm -rf .venv/ || true
        
        # Time UV environment creation
        echo "Timing UV environment creation..."
        start_time=$(date +%s.%N)
        uv sync
        end_time=$(date +%s.%N)
        uv_time=$(echo "$end_time - $start_time" | bc -l)
        
        echo "UV Environment Creation: ${uv_time}s"
        
        # Verify installation
        package_count=$(uv run pip list | wc -l)
        echo "Installed packages: $package_count"
        
        # Check if we meet performance targets
        if (( $(echo "$uv_time < 15.0" | bc -l) )); then
          echo "‚úÖ Performance target met (< 15s)"
        else
          echo "‚ùå Performance target missed (>= 15s)"
          exit 1
        fi
        
    - name: Run UV helper benchmarks
      run: |
        ./scripts/uv-helpers.sh benchmark || true
        ./scripts/uv-helpers.sh status
        
  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test, lint]
    
    services:
      redis:
        image: redis:7.0
        ports:
          - 6379:6379
        options: --health-cmd "redis-cli ping" --health-interval 10s --health-timeout 5s --health-retries 5
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up UV
      uses: astral-sh/setup-uv@v3
      
    - name: Install dependencies
      run: uv sync --all-extras --dev
      
    - name: Set up environment variables
      run: |
        echo "FLASK_ENV=testing" >> $GITHUB_ENV
        echo "DATABASE_URL=sqlite:///:memory:" >> $GITHUB_ENV
        echo "REDIS_URL=redis://localhost:6379/1" >> $GITHUB_ENV
        echo "JWT_SECRET_KEY=test-secret-key" >> $GITHUB_ENV
        
    - name: Verify environment setup
      run: ./scripts/env-setup.sh validate || echo "Environment validation skipped in CI"
      
    - name: Run integration tests (when implemented)
      run: |
        echo "Integration tests will be implemented in future phases"
        # uv run pytest tests/integration/ -v
        
    - name: Test development scripts
      run: |
        ./scripts/dev-commands.sh --help
        ./scripts/uv-helpers.sh health
        ./scripts/env-setup.sh status
        
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build, integration]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    environment: staging
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: dist-${{ github.sha }}
        path: dist/
        
    - name: Deploy to staging
      run: |
        echo "Staging deployment will be implemented when backend is ready"
        echo "Would deploy: $(ls dist/)"
        
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build, integration]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: production
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: dist-${{ github.sha }}
        path: dist/
        
    - name: Deploy to production
      run: |
        echo "Production deployment will be implemented when backend is ready"
        echo "Would deploy: $(ls dist/)"
        
  # Job to report overall status
  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: [test, lint, build, performance]
    if: always()
    
    steps:
    - name: Check job statuses
      run: |
        echo "Test Status: ${{ needs.test.result }}"
        echo "Lint Status: ${{ needs.lint.result }}"
        echo "Build Status: ${{ needs.build.result }}"
        echo "Performance Status: ${{ needs.performance.result }}"
        
        if [ "${{ needs.test.result }}" = "success" ] && \
           [ "${{ needs.lint.result }}" = "success" ] && \
           [ "${{ needs.build.result }}" = "success" ] && \
           [ "${{ needs.performance.result }}" = "success" ]; then
          echo "üéâ All CI jobs completed successfully!"
        else
          echo "‚ùå Some CI jobs failed"
          exit 1
        fi